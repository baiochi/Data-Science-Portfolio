{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "# terminal colors\n",
    "WHITE = '\\033[39m'\n",
    "CYAN = '\\033[36m'\n",
    "GREEN = '\\033[32m'\n",
    "RED = '\\033[31m'\n",
    "\n",
    "# color pallete\n",
    "colors = {\n",
    "    'cyan': '#1696d2',\n",
    "    'gray': '#5c5859',\n",
    "    'black': '#000000',\n",
    "    'yellow': '#fdbf11',\n",
    "    'orange': '#ca5800',\n",
    "    'magenta': '#af1f6b',\n",
    "    'green': '#408941',\n",
    "    'red': '#a4201d'\n",
    "}\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pandas config\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# libraries version\n",
    "print(f'Numpy: {np.__version__}')\n",
    "print(f'Pandas: {pd.__version__}')\n",
    "print(f'Sklearn: {sklearn.__version__}')\n",
    "print(f'Matplotlib: {matplotlib.__version__}')\n",
    "print(f'Seaborn: {sns.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents  \n",
    "- [Exploratory Data Analysis](#eda)  \n",
    "    - [Overview](#overview)  \n",
    "    - [Extracting Address Information](#address)  \n",
    "    - [Target Distribuition](#target)  \n",
    "- [Modeling](#modeling)  \n",
    "    - [Baseline](#cycle1)  \n",
    "    - [ElasticNet](#cycle2)  \n",
    "    - [XGBoost Regressor](#cycle3)  \n",
    "- [Deploy](#deploy)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id='eda' style='color:Gold'>Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='overview' style='color:#1696d2'>Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file **usa_housing.csv** consists of a dataset that contains information about the price of homes in certain regions of the United States. A description of the columns of this dataframe is presented below: \n",
    "  \n",
    "- Avg. Area Income: Average income of residents where the house is located.  \n",
    "- Avg. Area House Age: Average age of the houses in the same city.  \n",
    "- Avg. Area Number of Rooms: Average number of rooms for houses in the same city.  \n",
    "- Avg. Area Number of Bedrooms: Average number of bedrooms for houses in the same city.   \n",
    "- Area Population: Population of the city where the house is located. \n",
    "- Price: House selling price.  \n",
    "- Address: Address of the house.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://s3-sa-east-1.amazonaws.com/lcpi/7cf57d48-ac3d-4748-9d81-5b4d6677fcff.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='address' style='color:#1696d2'>Extracting data from Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 65\n",
    "string_sample = df.Address.sample(random_state=42).to_string(index=False)\n",
    "df.Address.sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(string_sample)\n",
    "city_sample  = ''.join( re.sub('[^a-zA-Z]+',\n",
    "                                ' ',\n",
    "                                string_sample.split('\\\\n')[-1]\n",
    "                            ).split()[:-1] )\n",
    "state_sample = re.sub('[^a-zA-Z]+', ' ', string_sample.split('\\n')[-1]).split()[-1]\n",
    "city_sample, state_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City'] = df.Address.apply( lambda address: ''.join(re.sub('[^a-zA-Z]+', ' ', address.split('\\n')[-1]).split()[:-1]) )\n",
    "df['State'] = df.Address.apply( lambda address: re.sub('[^a-zA-Z]+', ' ', address.split('\\n')[-1]).split()[-1] )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='target' style='color:#1696d2'>Target Variable - Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,6))\n",
    "sns.boxplot(y=df.Price, ax=ax[0])\n",
    "sns.histplot(df.Price, ax=ax[1], color=colors['gray'])\n",
    "plt.suptitle('Price Distribuition', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), cmap='coolwarm', annot=True, mask=np.triu(df.corr()))\n",
    "plt.title('Data correlation', size=18, pad=20, loc='left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id='modeling' style='color:Gold'>Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target and features (exclude categorical features for the first cycle)\n",
    "X = df.drop(['Price', 'Address', 'City', 'State'], axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "# split into traintest data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='cycle1' style='color:#1696d2'>First Cycle - Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statsmodels OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "sm_model = sm.OLS(y_train, X_train_const, hasconst = True).fit()\n",
    "sm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(f'Train r2_score: {metrics.r2_score(y_train, reg.predict(X_train)):.3f}')\n",
    "print(f'Test r2_score: {metrics.r2_score(y_test, reg.predict(X_test)):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='cycle2' style='color:#1696d2'>Second Cycle - ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn libraries import\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# pre-processing and estimator\n",
    "pipeline = Pipeline([\n",
    "                    ('std', StandardScaler()),\n",
    "                    ('regr', ElasticNet(random_state=42))\n",
    "])\n",
    "\n",
    "# gridsearch parameters\n",
    "param_grid = {\n",
    "    'regr__alpha' : np.linspace(0.5,10,20),\n",
    "    'regr__l1_ratio' : np.linspace(0,1,11),\n",
    "    'regr__max_iter' : [1000, 2000, 3000],\n",
    "    'regr__fit_intercept' : [True, False]\n",
    "}\n",
    "\n",
    "# metrics to evaluate\n",
    "metrics = 'neg_mean_absolute_error'\n",
    "\n",
    "# cross validation method\n",
    "splitter = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# create grid\n",
    "regr_grid = GridSearchCV(\n",
    "                        estimator=pipeline,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring=metrics,\n",
    "                        cv=splitter,\n",
    "                        verbose=10\n",
    ")\n",
    "\n",
    "# fit models\n",
    "regr_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(regr_grid.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with the best parameters\n",
    "regr_model = Pipeline([\n",
    "                    ('std', StandardScaler()),\n",
    "                    ('regr', ElasticNet(alpha=1.5, l1_ratio=1.0, random_state=42))\n",
    "                    ]).fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_train_pred = regr_model.predict(X_train)\n",
    "y_test_pred = regr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "display_metrics = lambda metric, y, y_pred: print(f'{CYAN}{metric.__name__}{WHITE}: {metric(y, y_pred):.3f}')\n",
    "\n",
    "print('Train metrics:')\n",
    "for metric in [r2_score, mean_absolute_error, mean_squared_error]:\n",
    "    display_metrics(metric, y_train, y_train_pred)\n",
    "\n",
    "print('Test metrics:')\n",
    "for metric in [r2_score, mean_absolute_error, mean_squared_error]:\n",
    "    display_metrics(metric, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean Absolute Error is {mean_absolute_error(y_test, y_test_pred) / y.mean() * 100:.2f}% of price mean.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.regplot(x=y_test, y=y_test_pred, marker='.', line_kws={\"color\": \"black\"})\n",
    "plt.xlabel('true price')\n",
    "plt.ylabel('predict price')\n",
    "plt.title('Relational plot between predict and true values', size=18, pad=20, loc='left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resids = y_test_pred - y_test\n",
    "fig, ax  = plt.subplots(1,2, figsize=(14,6))\n",
    "\n",
    "sns.scatterplot(x=y_test_pred, y=resids, s=20, ax=ax[0])\n",
    "ax[0].ticklabel_format(axis='Y', style='sci', scilimits=(0,0))\n",
    "ax[0].set_xlabel('Predict target')\n",
    "ax[0].set_ylabel('Resids')\n",
    "\n",
    "sns.distplot(x=resids, ax=ax[1])\n",
    "ax[1].ticklabel_format(axis='X', style='sci', scilimits=(0,0))\n",
    "\n",
    "plt.suptitle('Residual Error Distribuition', size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "coefs_df = pd.DataFrame(\n",
    "            data={\n",
    "                'Original': np.append(\n",
    "                                    '?', \n",
    "                                    (regr_model.named_steps['regr'].coef_ / regr_model.named_steps['std'].scale_).round(2)\n",
    "                            ),\n",
    "                'Scaled' : np.append(\n",
    "                                    regr_model.named_steps['regr'].intercept_.round(2), \n",
    "                                    regr_model.named_steps['regr'].coef_)\n",
    "                }, \n",
    "            index=['Intercept'] + X.columns.tolist()\n",
    "        )\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:1.5em'>$b0 + \\sum{b_i X_i} = \\tilde{b}_0 - \\sum{ \\frac{\\tilde{b_i}\\mu_i}{\\sigma_i}} + \\sum{\\frac{\\tilde{b_i}}{\\sigma_i} X_i}$  \n",
    "<br>\n",
    "<span style='color:orange'>coefficients:</span> <span style='font-size:1em'> $b_i = \\frac{\\tilde{b_i}}{\\sigma_i}$\n",
    "<br>\n",
    "<span style='color:orange'>intercept:</span> <span style='font-size:1em'> $b_0 = \\tilde{b_0} - \\sum{ \\frac{\\tilde{b_i}\\mu_i}{\\sigma_i}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0_til = regr_model.named_steps['regr'].intercept_  # scaled intercept\n",
    "bi_til = regr_model.named_steps['regr'].coef_       # scaled coefs\n",
    "mu_i = X_train.mean()                               # train dataset mean\n",
    "sigma_i = regr_model.named_steps['std'].scale_      # std used in StandardScaler\n",
    "\n",
    "b0 = b0_til - sum( (bi_til * mu_i) / sigma_i )      # unscaled intercept value\n",
    "\n",
    "print(f'{CYAN}Statsmodels Intercept:{WHITE} {sm_model.params[\"const\"]:.3f} | {CYAN}r2_score:{WHITE} {sm_model.rsquared}')\n",
    "print(f'{CYAN}Sklearn Intercept:{WHITE} {b0:.3f} | {CYAN}r2_score:{WHITE} {r2_score(y_train, y_train_pred)}') # score from train dataset to match sm_model\n",
    "print(f'{CYAN}Diff{WHITE} = {sm_model.params[\"const\"] - b0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=coefs_df['Scaled'], y=coefs_df.index)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Intercept**: With every params = 0, house price is $ 1,229,576.99  (or 2,635,057.82 ? )\n",
    "- **Avg. Area Income**:\n",
    "- **Avg. Area House Age**:\n",
    "- **Avg. Area Number of Rooms**:\n",
    "- **Avg. Area Number of Bedrooms**:\n",
    "- **Area Population**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model in pickle format\n",
    "with open('pickle/house_pricing_regr_model', 'wb') as file:\n",
    "    pickle.dump(regr_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='cycle3' style='color:#1696d2'>Third Cycle - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "                    ('std', StandardScaler()),\n",
    "                    ('xgb', XGBRegressor(random_state=42))\n",
    "                ])\n",
    "\n",
    "# gridsearch parameters\n",
    "param_grid = {\n",
    "    'xgb__n_estimators': [2,10,30,50,75,100,200],\n",
    "    'xgb__max_depth': range(1,6),\n",
    "    'xgb__reg_alpha' : np.linspace(0.5,10,10),\n",
    "    'xgb__reg_lambda' : np.linspace(0.5,10,10)\n",
    "}\n",
    "\n",
    "# metrics to evaluate\n",
    "metrics = 'neg_mean_absolute_error'\n",
    "\n",
    "# cross validation method\n",
    "splitter = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# create grid\n",
    "xgb_grid = GridSearchCV(\n",
    "                        estimator=xgb_pipeline,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring=metrics,\n",
    "                        cv=splitter,\n",
    "                        verbose=10\n",
    "            )\n",
    "\n",
    "xgb_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_xgb = xgb_grid.predict(X_train)\n",
    "y_test_pred_xgb = xgb_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train metrics:')\n",
    "for metric in [r2_score, mean_absolute_error, mean_squared_error]:\n",
    "    display_metrics(metric, y_train, y_train_pred_xgb)\n",
    "\n",
    "print('Test metrics:')\n",
    "for metric in [r2_score, mean_absolute_error, mean_squared_error]:\n",
    "    display_metrics(metric, y_test, y_test_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model in pickle format\n",
    "with open('pickle/house_pricing_xgb_model', 'wb') as file:\n",
    "    pickle.dump(xgb_grid, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: despite using a more complex regression model, score from the *Test* dataset was slightly lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id='deploy' style='color:Gold'>Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model data in pickle format\n",
    "with open('pickle/house_pricing_regr_model', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = 68200\n",
    "house_age = 6\n",
    "n_rooms = 7\n",
    "n_bedrooms = 4\n",
    "population = 30000\n",
    "\n",
    "input = [[income, house_age, n_rooms, n_bedrooms, population]]\n",
    "\n",
    "print(f'$ {model.predict(input)[0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "from ipywidgets import widgets, HBox, VBox\n",
    "\n",
    "# Criando os controles do formulário\n",
    "income = widgets.Text(description='Income')\n",
    "house_age = widgets.Text(description='House Age')\n",
    "n_rooms = widgets.Text(description='Number of Rooms')\n",
    "n_bedrooms = widgets.Text(description='Number of Bedrooms')\n",
    "population = widgets.Text(description='Population?')\n",
    "\n",
    "button = widgets.Button(description='Simulate')\n",
    "\n",
    "# Posicionando os controles\n",
    "left = VBox([income, house_age, n_rooms])\n",
    "right = VBox([n_bedrooms, population])\n",
    "inputs = HBox([left, right])\n",
    "\n",
    "# Função de simulação\n",
    "def simulator(sender):\n",
    "    input=[[\n",
    "            float(income.value if income.value else 0), \n",
    "            float(house_age.value if house_age.value else 0), \n",
    "            float(n_rooms.value if n_rooms.value else 0), \n",
    "            float(n_bedrooms.value if n_bedrooms.value else 0), \n",
    "            float(population.value if population.value else 0), \n",
    "             ]]\n",
    "    print(f'$ {model.predict(input)[0]:.2f}')\n",
    "\n",
    "# Atribuindo a função 'simulador' ao evento click do botão\n",
    "button.on_click(simulator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cc37c5bde6f2c4a9abbb0f88e1ba241d8320ce9d430498035b829e5a00e7fb9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
